{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from random import randint\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "import higra as hg\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import skimage as sk\n",
    "\n",
    "import datasets.I3 as D1\n",
    "import datasets.LW4 as D2\n",
    "import patch\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "LAMBDAS = []\n",
    "BATCH_SIZE = 512*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patches_batch_tos_area_p(batch_image, i, j, l):\n",
    "    tree, altitudes = hg.component_tree_tree_of_shapes_image2d(batch_image[i, :, :, 0])\n",
    "    area = hg.attribute_area(tree)\n",
    "    batch_image[i, :, :, j+1] = hg.reconstruct_leaf_data(tree, altitudes, area < l)\n",
    "    return batch_image[i, :, :, j+1]\n",
    "\n",
    "\n",
    "def gen_patches_batch_augmented_tos_area_label_random_one_hot_p(patch_size, image, label, batch_size=32, lambdas=[]):\n",
    "    n_label = label[0].shape[-1]\n",
    "    batch_image = np.zeros((batch_size, patch_size, patch_size, len(lambdas)+1))\n",
    "    batch_label = np.zeros((batch_size, patch_size, patch_size, n_label))\n",
    "    pool = mp.Pool(min(mp.cpu_count(), 16))\n",
    "    while True:\n",
    "        for i in range(batch_size):\n",
    "            x = randint(0, image.shape[2] - patch_size - 1)\n",
    "            y = randint(0, image.shape[1] - patch_size - 1)\n",
    "            z = randint(0, image.shape[0] - 1)\n",
    "            \n",
    "            batch_image[i, :, :, 0] = image[z, y:y + patch_size, x:x + patch_size]\n",
    "            batch_label[i, :, :, :] = label[z, y:y + patch_size, x:x + patch_size]\n",
    "            \n",
    "            # Augmentations\n",
    "            # random 90 degree rotation\n",
    "            # random flip\n",
    "            rot = randint(0, 3)\n",
    "            batch_image[i, :, :] = np.rot90(batch_image[i, :, :], rot)\n",
    "            batch_label[i, :, :] = np.rot90(batch_label[i, :, :], rot)\n",
    "            \n",
    "            if randint(0, 1) == 1:\n",
    "                batch_image[i, :, :] = np.fliplr(batch_image[i, :, :])\n",
    "                batch_label[i, :, :] = np.fliplr(batch_label[i, :, :])\n",
    "                \n",
    "            if randint(0, 1) == 1:\n",
    "                batch_image[i, :, :] = np.flipud(batch_image[i, :, :])\n",
    "                batch_label[i, :, :] = np.flipud(batch_label[i, :, :])\n",
    "        \n",
    "        batch_image_p = (pool.starmap(patches_batch_tos_area_p, [(batch_image, ij//len(lambdas), ij%len(lambdas), lambdas[ij%len(lambdas)]) for ij in range(batch_size * len(lambdas))]))\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            for j in range(len(lambdas)):\n",
    "                x = j + i*len(lambdas)\n",
    "                batch_image[i, :, :, j+1] = batch_image_p[x]\n",
    "        \n",
    "        del batch_image_p\n",
    "        \n",
    "        yield batch_image, batch_label\n",
    "    pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = D1.train_i3_image_normalized_f32\n",
    "train_labels = np.sum([D1.train_i3_label_1, D1.train_i3_label_2*2, D1.train_i3_label_3*3], axis=0).astype(np.uint8)\n",
    "train_background = np.where(train_labels > 0, 0, 1)\n",
    "train_labels_indexes = [D1.train_i3_label_1_indexes, D1.train_i3_label_2_indexes, D1.train_i3_label_3_indexes]\n",
    "train_labels_one_hot = np.stack([train_background, D1.train_i3_label_1, D1.train_i3_label_2, D1.train_i3_label_3], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = patch.gen_patches_batch_augmented_tos_area_label_indexes_one_hot_p(PATCH_SIZE, train_image, train_labels_one_hot, train_labels_indexes, batch_size=BATCH_SIZE, lambdas=LAMBDAS)\n",
    "train2 = gen_patches_batch_augmented_tos_area_label_random_one_hot_p(PATCH_SIZE, train_image, train_labels_one_hot, batch_size=BATCH_SIZE, lambdas=LAMBDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(train1)\n",
    "print((np.sum(Y[:, :, :, 0])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 1])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 2])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 3])/(256*256))*100/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 77.57105976343155\n",
    "* 14.720947295427322\n",
    "* 1.1825524270534515\n",
    "* 6.525498628616333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(train2)\n",
    "print((np.sum(Y[:, :, :, 0])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 1])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 2])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 3])/(256*256))*100/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 92.0101523399353\n",
    "* 5.138735473155975\n",
    "* 0.323670357465744\n",
    "* 2.5274470448493958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image = D2.train_lw4_image_normalized_f32\n",
    "train_labels = np.sum([D2.train_lw4_label_1, D2.train_lw4_label_2*2, D2.train_lw4_label_3*3], axis=0).astype(np.uint8)\n",
    "train_background = np.where(train_labels > 0, 0, 1)\n",
    "train_labels_indexes = [D2.train_lw4_label_1_indexes, D2.train_lw4_label_2_indexes, D2.train_lw4_label_3_indexes]\n",
    "train_labels_one_hot = np.stack([train_background, D2.train_lw4_label_1, D2.train_lw4_label_2, D2.train_lw4_label_3], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = patch.gen_patches_batch_augmented_tos_area_label_indexes_one_hot_p(PATCH_SIZE, train_image, train_labels_one_hot, train_labels_indexes, batch_size=BATCH_SIZE, lambdas=LAMBDAS)\n",
    "train2 = gen_patches_batch_augmented_tos_area_label_random_one_hot_p(PATCH_SIZE, train_image, train_labels_one_hot, batch_size=BATCH_SIZE, lambdas=LAMBDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(train1)\n",
    "print((np.sum(Y[:, :, :, 0])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 1])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 2])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 3])/(256*256))*100/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 84.41567122936249\n",
    "* 9.082133322954178\n",
    "* 2.6188924908638\n",
    "* 3.8833029568195343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(train2)\n",
    "print((np.sum(Y[:, :, :, 0])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 1])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 2])/(256*256))*100/BATCH_SIZE)\n",
    "print((np.sum(Y[:, :, :, 3])/(256*256))*100/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 90.60298949480057\n",
    "* 5.268880724906921\n",
    "* 1.3633936643600464\n",
    "* 2.7647361159324646"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tf230",
   "language": "python",
   "name": "venv_tf230"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
